{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8edc08a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import custom libraries from local folder.\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from calib import EventDataset\n",
    "from calib.nn import ConjunctionEventForecaster as CEF\n",
    "from calib.data import kelvins_to_event_dataset\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential of layers: \n",
      "(0) RNNlayer: Linear(in_features=50, out_features=100, bias=True)\n",
      "(1) ReLU(inplace=True)\n",
      "(2) <function pack_padded_sequence at 0x11ba7d8b0>\n",
      "(3) RNNlayer: LSTM(100, 200, num_layers=2, batch_first=True, dropout=0.2)\n",
      "(4) <function pad_packed_sequence at 0x11ba66160>\n",
      "(5) Dropout(p=0.2, inplace=True)\n",
      "(6) ReLU(inplace=True)\n",
      "(7) RNNlayer: Linear(in_features=200, out_features=100, bias=True)\n",
      "(8) ReLU(inplace=True)\n",
      "(9) RNNlayer: Linear(in_features=25, out_features=25, bias=True)\n"
     ]
    }
   ],
   "source": [
    "# Import json library and create function to format dictionaries.\n",
    "import json\n",
    "format_json = lambda x: json.dumps(x, indent=4)\n",
    "\n",
    "class RNNlayer():\n",
    "    def __init__(self, layer_type:str, input_size:int, \n",
    "                 output_size:int, **kwargs):\n",
    "\n",
    "        # Check layer_type is either linear or lstm.\n",
    "        if not layer_type in ['lstm', 'linear']:\n",
    "            raise ValueError('Layer {} not recognised'.format(layer_type))\n",
    "\n",
    "        self.layer_type = layer_type\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        # Set internal values for the model.\n",
    "        for key, value in kwargs.items(): setattr(self, '_' + key, value)\n",
    "\n",
    "\n",
    "        if layer_type == 'lstm':\n",
    "\n",
    "            default_parameters = dict(num_layers=2, batch_first=True, dropout=0)\n",
    "            for parameter, value in default_parameters.items():\n",
    "                if not parameter in kwargs.keys():\n",
    "                    print('Parameter {} missing in the class. Setting ' \\\n",
    "                          'default value ({}).'.format(parameter, value))\n",
    "\n",
    "            \n",
    "            self.layer = nn.LSTM(input_size = self.input_size, \n",
    "                            hidden_size     = self.output_size, \n",
    "                            num_layers      = kwargs.get('num_layers',2), \n",
    "                            batch_first     = kwargs.get('batch_first', True), \n",
    "                            dropout         = kwargs.get('dropout', 0),\n",
    "                            bias            = kwargs.get('bias', True),\n",
    "                            bidirectional   = kwargs.get('bidirectional', False),\n",
    "                            proj_size       = kwargs.get('proj_size', 0))\n",
    "\n",
    "        elif layer_type == 'linear':\n",
    "\n",
    "            self.layer = nn.Linear(in_features  = self.input_size, \n",
    "                                  out_features  = self.output_size,\n",
    "                                  bias          = kwargs.get('bias', True), \n",
    "                                  device        = kwargs.get('device', None), \n",
    "                                  dtype         = kwargs.get('dtype', None))\n",
    "\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        \"\"\"Print readable information about the layer.\n",
    "\n",
    "        Returns:\n",
    "            str: Class name with number of CDMs objects contained on it.\n",
    "        \"\"\"\n",
    "        return 'RNNlayer: {}'.format(self.layer)\n",
    "\n",
    "    def __getitem__(self):\n",
    "        \"\"\"Get layer object.\n",
    "        \"\"\"\n",
    "        return self.layer\n",
    "\n",
    "\n",
    "def pack_padded_sequence(x, x_lengths):\n",
    "\n",
    "    return nn.utils.rnn.pack_padded_sequence(input = x, \n",
    "                                              lengths = x_lengths, \n",
    "                                              batch_first=True, \n",
    "                                              enforce_sorted=False)\n",
    "\n",
    "def pad_packed_sequence(x, x_length_max):\n",
    "\n",
    "    # Pads a packed batch of variable length sequences from LSTM layer.\n",
    "    x, _ = nn.utils.rnn.pad_packed_sequence(sequence = x, \n",
    "                                            batch_first=True, \n",
    "                                            total_length = x_length_max)\n",
    "    return x   \n",
    "\n",
    "\n",
    "# Define input and output size of the RNN model.\n",
    "input_size = 50\n",
    "output_size = 25\n",
    "\n",
    "# Define parameter batch_first for batch processing.\n",
    "batch_first = True\n",
    "\n",
    "# Define number of output neurons per layer.\n",
    "layers = [dict(layer_type = 'linear', \n",
    "               output_size = 100), \n",
    "          dict(layer_type = 'lstm', \n",
    "                output_size = 200, \n",
    "                batch_first = batch_first,\n",
    "                num_layers = 2,\n",
    "                dropout = 0.2), \n",
    "          dict(layer_type = 'linear', \n",
    "               output_size = 100)]\n",
    "\n",
    "layerlist = []\n",
    "for l, layer in enumerate(layers):\n",
    "\n",
    "    kwargs = {}\n",
    "    for key, value in layer.items():\n",
    "        if key in ['layer_type', 'input_size', 'output_size']: continue\n",
    "        kwargs[key] = value\n",
    "\n",
    "    if layer['layer_type']=='lstm': \n",
    "        layerlist.append(pack_padded_sequence)\n",
    "\n",
    "    i_layer = RNNlayer(layer_type = layer['layer_type'],\n",
    "                       input_size = input_size, \n",
    "                       output_size = layer['output_size'],\n",
    "                       **kwargs)\n",
    "\n",
    "    # Append i_layer object to list\n",
    "    layerlist.append(i_layer)\n",
    "\n",
    "    if layer['layer_type']=='lstm': \n",
    "        layerlist.append(pad_packed_sequence)\n",
    "\n",
    "    # Cancel out a random proportion p of the neurons to avoid overfitting\n",
    "    if 'dropout' in kwargs.keys():\n",
    "        layerlist.append(nn.Dropout(kwargs.get('dropout', 0), inplace = True))\n",
    "\n",
    "    # Apply ReLU activation function (al(z))\n",
    "    layerlist.append(nn.ReLU(inplace=True))\n",
    "    \n",
    "\n",
    "    # Define input_size for the next layer.\n",
    "    input_size = layer['output_size']\n",
    "\n",
    "\n",
    "last_layer = RNNlayer(layer_type = 'linear', \n",
    "                   input_size = output_size,\n",
    "                   output_size = output_size)\n",
    "\n",
    "layerlist.append(last_layer)\n",
    "\n",
    "print('Sequential of layers: ')\n",
    "for l, layer in enumerate(layerlist):\n",
    "    print('({}) {}'.format(l, layer))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading\n",
    "\n",
    "Kessler accepts CDMs either in KVN format or as pandas dataframes. We hereby show a pandas dataframe loading example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Kelvins dataset from file name: /Users/jjrr/Documents/SCA-Project/Tool/data/esa-challenge/train_data.csv\n",
      "162634 entries\n",
      "Dropping features: ['c_rcs_estimate', 't_rcs_estimate']\n",
      "Dropping rows with NaNs\n",
      "146571 entries\n",
      "Removing outliers\n",
      "127037 entries\n",
      "Shuffling\n",
      "Grouped rows into 9586 events\n",
      "Taking TCA as current time: 2023-07-21 13:22:02.766396\n",
      "Converting Kelvins challenge data to EventDataset\n",
      "Time spent  | Time remain.| Progress             | Events    | Events/sec\n",
      "0d:00:00:04 | 0d:00:00:00 | #################### | 1000/1000 | 228.88       \n"
     ]
    }
   ],
   "source": [
    "#As an example, we first show the case in which the data comes from the Kelvins competition.\n",
    "#For this, we built a specific converter that takes care of the conversion from Kelvins format\n",
    "#to standard CDM format (the data can be downloaded at https://kelvins.esa.int/collision-avoidance-challenge/data/):\n",
    "file_name = '/Users/jjrr/Documents/SCA-Project/calib/data/esa-challenge/train_data.csv'\n",
    "events = kelvins_to_event_dataset(file_name, drop_features=['c_rcs_estimate', 't_rcs_estimate'], num_events=1000) #we use only 200 events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instead, this is a generic real CDM data loader that should parse your Pandas (uncomment the following lines if needed):\n",
    "#file_name = 'path_to_csv/file.csv'\n",
    "\n",
    "#df=pd.read_csv(file_name)\n",
    "#events = EventDataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Descriptive statistics of the event:\n",
    "kessler_stats = events.to_dataframe().describe()\n",
    "print(kessler_stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We only use features with numeric content for the training\n",
    "#nn_features is a list of the feature names taken into account for the training:\n",
    "#it can be edited in case more features want to be added or removed\n",
    "nn_features = events.common_features(only_numeric=True)\n",
    "print(nn_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into a test set (5% of the total number of events)\n",
    "len_test_set=int(0.05*len(events))\n",
    "print('Test data:', len_test_set)\n",
    "events_test=events[-len_test_set:]\n",
    "print(events_test)\n",
    "\n",
    "# The rest of the data will be used for training and validation\n",
    "print('Training and validation data:', len(events)-len_test_set)\n",
    "events_train_and_val=events[:-len_test_set]\n",
    "print(events_train_and_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an LSTM predictor, specialized to the nn_features we extracted above\n",
    "model = CEF(\n",
    "            lstm_size=256,  # Number of hidden units per LSTM layer\n",
    "            lstm_depth=2,  # Number of stacked LSTM layers\n",
    "            dropout=0.2,  # Dropout probability\n",
    "            features=nn_features)  # The list of feature names to use in the LSTM\n",
    "\n",
    "# Start training\n",
    "model.learn(events_train_and_val, \n",
    "            epochs=10, # Number of epochs (one epoch is one full pass through the training dataset)\n",
    "            lr=1e-3, # Learning rate, can decrease it if training diverges\n",
    "            batch_size=16, # Minibatch size, can be decreased if there are issues with memory use\n",
    "            device='cpu', # Can be 'cuda' if there is a GPU available\n",
    "            valid_proportion=0.15, # Proportion of the data to use as a validation set internally\n",
    "            num_workers=4, # Number of multithreaded dataloader workers, 4 is good for performance, but if there are any issues or errors, please try num_workers=1 as this solves issues with PyTorch most of the time\n",
    "            event_samples_for_stats=1000) # Number of events to use to compute NN normalization factors, have this number as big as possible (and at least a few thousands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the model to a file after training:\n",
    "model.save(file_name=\"models/rnn/LSTM_20epochs_lr10-4_batchsize16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NN loss plotted to a file:\n",
    "model.plot_loss(file_name='images/plot_loss.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we show an example CDM from the set:\n",
    "events_train_and_val[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we take a single event, we remove the last CDM and try to predict it\n",
    "event=events_test[3]\n",
    "event_len = len(event)\n",
    "print(event)\n",
    "event_beginning = event[0:event_len-1]\n",
    "print(event_beginning)\n",
    "event_evolution = model.predict_event(event_beginning, num_samples=100, max_length=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We plot the prediction in red:\n",
    "axs = event_evolution.plot_features(['RELATIVE_SPEED', 'MISS_DISTANCE', 'OBJECT1_CT_T'], return_axs=True, linewidth=0.1, color='red', alpha=0.33, label='Prediction')\n",
    "#and the ground truth value in blue:\n",
    "event.plot_features(['RELATIVE_SPEED', 'MISS_DISTANCE', 'OBJECT1_CT_T'], axs=axs, label='Real', legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we now plot the uncertainty prediction for all the covariance matrix elements of both OBJECT1 and OBJECT2:\n",
    "axs = event_evolution.plot_uncertainty(return_axs=True, linewidth=0.5, label='Prediction', alpha=0.5, color='red', legend=True, diagonal=False)\n",
    "event.plot_uncertainty(axs=axs, label='Real', diagonal=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
